{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5e41d6",
   "metadata": {},
   "source": [
    "## Implementing Layer Scale\n",
    "\n",
    "This is the first building block that we'll create in order to build up to a self-attention block.\n",
    "\n",
    "If you're wondering why PE uses a Layer Scale read this paper [Going Deeper with Image Transformers](https://arxiv.org/pdf/2103.17239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fece697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import inspect # We'll store the actual code .py files instead of the notebook.\n",
    "\n",
    "import torch\n",
    "import tvm\n",
    "import numpy as np\n",
    "\n",
    "from pe import LayerScale\n",
    "from compile import compile\n",
    "from utils import select_params\n",
    "\n",
    "PE_SPATIAL = '/home/jq/Storage/Model-Weights/HuggingFace-Cache/PE-Spatial-G14-448.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9d75965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected transformer.resblocks.42.ls_1.gamma: (1536,)\n"
     ]
    }
   ],
   "source": [
    "device = tvm.device('cuda', 0)\n",
    "param_name = 'transformer.resblocks.42.ls_1.gamma'\n",
    "state_dict = torch.load(PE_SPATIAL)\n",
    "\n",
    "params = select_params(param_name, state_dict).numpy()\n",
    "mod = LayerScale(params.shape[0])\n",
    "mod, params\n",
    "\n",
    "print(f\"Selected {param_name}: {params.shape}\")\n",
    "\n",
    "mod, packed_params = mod.export_tvm(spec=mod.get_default_spec())\n",
    "vm = compile(mod, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "731b3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tvm.nd.array(np.random.randint(0,10, params.shape[0], dtype=np.int32),device=device)\n",
    "y = vm['forward'](x, [tvm.nd.array(params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d15e8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class LayerScale(nn.Module):\n",
      "    def __init__(self, dim, init_values: float = 1e-5, inplace: bool =False):\n",
      "        super().__init__()\n",
      "        self.inplace = inplace\n",
      "        self.dim = dim\n",
      "        self.init_values = init_values\n",
      "\n",
      "    def forward(self, x):\n",
      "        # We'll need the learned gamma parameter\n",
      "        return x\n",
      "\n",
      "    def get_default_spec(self):\n",
      "        mod_spec = {\n",
      "            \"forward\": {\n",
      "                \"x\": nn.spec.Tensor([\"n\"], \"int32\")\n",
      "            },\n",
      "            \"$\": {\n",
      "                \"param_mode\": \"packed\",\n",
      "                \"effect_mode\": \"none\"\n",
      "                \n",
      "            }\n",
      "        }\n",
      "        return nn.spec.ModuleSpec.from_raw(mod_spec, self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(LayerScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efdb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e7937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02356c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm-perception-encoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
